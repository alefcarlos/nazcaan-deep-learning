{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Nazcaan classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "This tutorial shows how to classify Naazcan script. It creates an image classifier using a `keras.Sequential` model, and loads data using `preprocessing.image_dataset_from_directory`. You will gain practical experience with the following concepts:\n",
    "\n",
    "* Efficiently loading a dataset off disk.\n",
    "* Identifying overfitting and applying techniques to mitigate it, including data augmentation and Dropout.\n",
    "\n",
    "This tutorial follows a basic machine learning workflow:\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Test the model\n",
    "6. Improve the model and repeat the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:21.302568Z",
     "iopub.status.busy": "2021-01-08T05:00:21.301978Z",
     "iopub.status.idle": "2021-01-08T05:00:27.183449Z",
     "shell.execute_reply": "2021-01-08T05:00:27.183886Z"
    },
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:27.189625Z",
     "iopub.status.busy": "2021-01-08T05:00:27.189024Z",
     "iopub.status.idle": "2021-01-08T05:00:30.598479Z",
     "shell.execute_reply": "2021-01-08T05:00:30.597856Z"
    },
    "id": "57CcilYSG0zv"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(\"dataset\")\n",
    "data_dir"
   ]
  },
  {
   "source": [
    "Print total images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:30.603139Z",
     "iopub.status.busy": "2021-01-08T05:00:30.602470Z",
     "iopub.status.idle": "2021-01-08T05:00:30.616212Z",
     "shell.execute_reply": "2021-01-08T05:00:30.615717Z"
    },
    "id": "SbtTDYhOHZb6"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.PNG')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVmwkOSdHZ5A"
   },
   "source": [
    "Here are some zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:30.620036Z",
     "iopub.status.busy": "2021-01-08T05:00:30.619489Z",
     "iopub.status.idle": "2021-01-08T05:00:30.724439Z",
     "shell.execute_reply": "2021-01-08T05:00:30.724813Z"
    },
    "id": "N1loMlbYHeiJ"
   },
   "outputs": [],
   "source": [
    "zeros = list(data_dir.glob('0/*'))\n",
    "PIL.Image.open(str(zeros[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGEqiBbRHnyI"
   },
   "source": [
    "And some nines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:30.788168Z",
     "iopub.status.busy": "2021-01-08T05:00:30.787632Z",
     "iopub.status.idle": "2021-01-08T05:00:30.843120Z",
     "shell.execute_reply": "2021-01-08T05:00:30.843506Z"
    },
    "id": "HyQkfPGdHilw"
   },
   "outputs": [],
   "source": [
    "nines = list(data_dir.glob('9/*'))\n",
    "PIL.Image.open(str(nines[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIjgz7_JIo_m"
   },
   "source": [
    "# Load using keras.preprocessing\n",
    "\n",
    "Let's load these images off disk using the helpful [image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) utility. This will take you from a directory of images on disk to a `tf.data.Dataset` in just a couple lines of code. If you like, you can also write your own data loading code from scratch by visiting the [load images](https://www.tensorflow.org/tutorials/load_data/images) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyDNn9MbIzfT"
   },
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anqiK_AGI086"
   },
   "source": [
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:30.871161Z",
     "iopub.status.busy": "2021-01-08T05:00:30.870601Z",
     "iopub.status.idle": "2021-01-08T05:00:30.872349Z",
     "shell.execute_reply": "2021-01-08T05:00:30.872704Z"
    },
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "img_height = 130\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFBhRrrEI49z"
   },
   "source": [
    "It's good practice to use a validation split when developing your model. Let's use 80% of the images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:30.876664Z",
     "iopub.status.busy": "2021-01-08T05:00:30.875983Z",
     "iopub.status.idle": "2021-01-08T05:00:32.553310Z",
     "shell.execute_reply": "2021-01-08T05:00:32.553729Z"
    },
    "id": "fIR0kRZiI_AT"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLQULyAvJC3X"
   },
   "source": [
    "You can find the class names in the `class_names` attribute on these datasets. These correspond to the directory names in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:32.683843Z",
     "iopub.status.busy": "2021-01-08T05:00:32.683202Z",
     "iopub.status.idle": "2021-01-08T05:00:32.685744Z",
     "shell.execute_reply": "2021-01-08T05:00:32.686114Z"
    },
    "id": "ZHAxkHX5JD3k"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:32.558701Z",
     "iopub.status.busy": "2021-01-08T05:00:32.558077Z",
     "iopub.status.idle": "2021-01-08T05:00:32.679595Z",
     "shell.execute_reply": "2021-01-08T05:00:32.679949Z"
    },
    "id": "iscU3UoVJBXj"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqtyGodAMvNV"
   },
   "source": [
    "## Overfitting"
   ]
  },
  {
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "  ]\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "typeof"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_augmentation)"
   ]
  },
  {
   "source": [
    "Visualize traind data with data_augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "source": [
    "Visualize validation images with data_augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in val_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uoVvxSLJW9m"
   },
   "source": [
    "## Visualize the data\n",
    "\n",
    "Here are the first 5 images from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:32.693419Z",
     "iopub.status.busy": "2021-01-08T05:00:32.692462Z",
     "iopub.status.idle": "2021-01-08T05:00:33.672462Z",
     "shell.execute_reply": "2021-01-08T05:00:33.673035Z"
    },
    "id": "wBmEA9c0JYes"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(5):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUTyDOPKucd"
   },
   "source": [
    "# Create the model\n",
    "\n",
    "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 128 units on top of it that is activated by a `relu` activation function. This model has not been tuned for high accuracy, the goal of this tutorial is to show a standard approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:38.933748Z",
     "iopub.status.busy": "2021-01-08T05:00:38.928344Z",
     "iopub.status.idle": "2021-01-08T05:00:38.983967Z",
     "shell.execute_reply": "2021-01-08T05:00:38.983462Z"
    },
    "id": "QR6argA1K074"
   },
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaKFzz72Lqpg"
   },
   "source": [
    "## Compile the model\n",
    "\n",
    "For this tutorial, choose the `optimizers.Adam` optimizer and `losses.SparseCategoricalCrossentropy` loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:38.990270Z",
     "iopub.status.busy": "2021-01-08T05:00:38.989679Z",
     "iopub.status.idle": "2021-01-08T05:00:39.004344Z",
     "shell.execute_reply": "2021-01-08T05:00:39.003890Z"
    },
    "id": "jloGNS1MLx3A"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMJ4DnuJL55A"
   },
   "source": [
    "## Model summary\n",
    "\n",
    "View all the layers of the network using the model's `summary` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:39.008124Z",
     "iopub.status.busy": "2021-01-08T05:00:39.007522Z",
     "iopub.status.idle": "2021-01-08T05:00:39.012798Z",
     "shell.execute_reply": "2021-01-08T05:00:39.013203Z"
    },
    "id": "llLYH-BXL7Xe"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiYHcbvaL9H-"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:39.017182Z",
     "iopub.status.busy": "2021-01-08T05:00:39.016534Z",
     "iopub.status.idle": "2021-01-08T05:00:52.703039Z",
     "shell.execute_reply": "2021-01-08T05:00:52.703406Z"
    },
    "id": "5fWToCqYMErH"
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyFKdQpXMJT4"
   },
   "source": [
    "## Visualize training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFvOvmAmMK9w"
   },
   "source": [
    "Create plots of loss and accuracy on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:00:52.726858Z",
     "iopub.status.busy": "2021-01-08T05:00:52.721986Z",
     "iopub.status.idle": "2021-01-08T05:00:52.943458Z",
     "shell.execute_reply": "2021-01-08T05:00:52.943861Z"
    },
    "id": "jWnopEChMMCn"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10buWpJbcCQz"
   },
   "source": [
    "Finally, let's use our model to classify an image that wasn't included in the training or validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKgMZ4bDcHf7"
   },
   "source": [
    "Note: Data augmentation and Dropout layers are inactive at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T05:01:10.560857Z",
     "iopub.status.busy": "2021-01-08T05:01:10.560231Z",
     "iopub.status.idle": "2021-01-08T05:01:10.921318Z",
     "shell.execute_reply": "2021-01-08T05:01:10.920799Z"
    },
    "id": "dC40sRITBSsQ"
   },
   "outputs": [],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/alefcarlos/nazcaan-deep-learning/main/dataset/3/image.PNG\"\n",
    "predicte_image_path = tf.keras.utils.get_file('predictImage', origin=image_url)\n",
    "\n",
    "print(predicte_image_path)\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    predicte_image_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "source": [
    "End"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('myenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e6f2da8c8b1f6d10cc28c750605b73c7c9c04ca25445637f5717e4c91b95ef1a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}